# ACL 2018

Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation. Tiancheng Zhao, Kyusong Lee, Maxine Eskenazi.

 Word Embedding and WordNet Based Metaphor Identification and Interpretation. Rui Mao, Chenghua Lin, Frank Guerin.

 Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder. Ryo Takahashi, Ran Tian, Kentaro Inui.

Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph. AmirAli Bagher Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, Louis-Philippe Morency.

Automatic Estimation of Simultaneous Interpreter Performance. Craig Stewart, Nikolai Vogler, Junjie Hu, Jordan Boyd-Graber, Graham Neubig.

# ACL 2017

An Interpretable Knowledge Transfer Model for Knowledge Base Completion Qizhe Xie, Xuezhe Ma, Zihang Dai and Eduard Hovy

Sarcasm SIGN: Interpreting Sarcasm with Sentiment Based Monolingual Machine Translation Lotem Peled and Roi Reichart

Information-Theory Interpretation of the Skip-Gram Negative-Sampling Objective Function Oren Melamud and Jacob Goldberger

# ICLR 2018

Hierarchical and Interpretable Skill Acquisition in Multi-task 

Reinforcement Learning
Interpretable Counting for Visual Question Answering

# ICML 2018

Varia onal Bayes and Beyond:Bayesian Inference for Big DataTamara Broderick (MIT)
Loca on: Victoria

Learning to Explain: An Information Theoretic Perspective on Model Interpretation
Jianbo Chen, Le Song, Marn Wainwright, Michael Jordan

Discovering Interpretable Representa ons for BothDeep Genera ve and Discrimina ve ModelsTameem Adel, Zoubin Ghahramani, Adrian Weller

Programma cally Interpretable Reinforcement Learning
Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh,Pushmeet Kohli, Swarat Chaudhuri

Differentiable Abstract Interpreta on for Provably RobustNeural Networks
Ma hew Mirman, Timon Gehr, Mar n Veche

Interpretability Beyond Feature A ribu on:Quan ta ve Tes ng with Concept Ac va on Vectors(TCAV)
Been Kim, Mar n Wa enberg, Jus n Gilmer, Carrie Cai,James Wexler, Fernanda B Vi√©gas, Rory sayres

oi-VAE: Output Interpretable VAEs for Nonlinear GroupFactor Analysis
Samuel Ainsworth, Nick J Fo , Adrian KC Lee, Emily Fox

Fairness, Interpretability, and Explainability Federa on of Workshops


# NeurIPS 2018

Towards Robust Interpretability with Self-Explaining Neural Networks

Representer Point Selection for Explaining Deep Neural Networks
Explaining Deep Learning Models -- A Bayesian Non-parametric Approach

Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections

Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability

Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples

Learning Conditioned Graph Structures for Interpretable Visual Question Answering

Diminishing Returns Shape Constraints for Interpretability and Regularization

Uncertainty-Aware Attention for Reliable Interpretation and Prediction

